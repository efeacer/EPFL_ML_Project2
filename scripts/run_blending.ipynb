{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Optimal Weights for Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from baselines import Baselines\n",
    "from MF_SGD import MF_SGD\n",
    "from MF_BSGD import MF_BSGD\n",
    "from MF_ALS import MF_ALS\n",
    "from surprise_models import SurpriseModels\n",
    "from blending import Blending\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed to be able to reproduce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data ...\n",
      "Splitting data to train and test data ...\n",
      "... data is splitted.\n",
      "... data is prepared.\n"
     ]
    }
   ],
   "source": [
    "data = Data(test_purpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary for the models to blend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelling using baseline_global_mean:\n",
      "Test RMSE using baseline_global_mean: 1.1217510250034082\n",
      "\n",
      "Modelling using baseline_user_mean:\n",
      "Test RMSE using baseline_user_mean: 1.096396482836658\n",
      "\n",
      "Modelling using baseline_movie_mean:\n",
      "Test RMSE using baseline_item_mean: 1.0308878155269185\n",
      "\n",
      "Modelling using baseline_global_median:\n",
      "Test RMSE using baseline_global_median: 1.130537396215373\n",
      "\n",
      "Modelling using baseline_user_median:\n",
      "Test RMSE using baseline_user_median: 1.1515699986539643\n",
      "\n",
      "Modelling using baseline_movie_median:\n",
      "Test RMSE using baseline_item_median: 1.0984206090659812\n"
     ]
    }
   ],
   "source": [
    "baselines = Baselines(data=data, test_purpose=True)\n",
    "\n",
    "print('\\nModelling using baseline_global_mean:')\n",
    "models['baseline_global_mean'] = baselines.baseline_global_mean()['Rating']\n",
    "\n",
    "print('\\nModelling using baseline_user_mean:')\n",
    "models['baseline_user_mean'] = baselines.baseline_user_mean()['Rating']\n",
    "\n",
    "print('\\nModelling using baseline_movie_mean:')\n",
    "models['baseline_item_mean'] = baselines.baseline_item_mean()['Rating']\n",
    "\n",
    "print('\\nModelling using baseline_global_median:')\n",
    "models['baseline_global_median'] = baselines.baseline_global_median()['Rating']\n",
    "\n",
    "print('\\nModelling using baseline_user_median:')\n",
    "models['baseline_user_median'] = baselines.baseline_user_median()['Rating']\n",
    "\n",
    "print('\\nModelling using baseline_movie_median:')\n",
    "models['baseline_item_median'] = baselines.baseline_item_median()['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Matrix Factorization model trained using Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelling using MF_SGD:\n",
      "Learning the matrix factorization using SGD ...\n",
      "Iteration: 1, RMSE on training set: 1.0160678051052041\n",
      "Iteration: 2, RMSE on training set: 1.007356323368439\n",
      "Iteration: 3, RMSE on training set: 1.0004793119769244\n",
      "Iteration: 4, RMSE on training set: 0.9955558890929159\n",
      "Iteration: 5, RMSE on training set: 0.9917812226205461\n",
      "Iteration: 6, RMSE on training set: 0.9884934261639605\n",
      "Iteration: 7, RMSE on training set: 0.9859018403955917\n",
      "Iteration: 8, RMSE on training set: 0.982875352018487\n",
      "Iteration: 9, RMSE on training set: 0.9804447964872828\n",
      "Iteration: 10, RMSE on training set: 0.9794597522010847\n",
      "Iteration: 11, RMSE on training set: 0.9774870835122362\n",
      "Iteration: 12, RMSE on training set: 0.9768867592093701\n",
      "Iteration: 13, RMSE on training set: 0.9755857527900949\n",
      "Iteration: 14, RMSE on training set: 0.9746623618252294\n",
      "Iteration: 15, RMSE on training set: 0.9741756825755195\n",
      "Iteration: 16, RMSE on training set: 0.9735984975199187\n",
      "Iteration: 17, RMSE on training set: 0.9732572621915615\n",
      "Iteration: 18, RMSE on training set: 0.9726658285677308\n",
      "Iteration: 19, RMSE on training set: 0.9722548129442251\n",
      "Iteration: 20, RMSE on training set: 0.9722090640787552\n",
      "The training process converged to a threshold.\n",
      "... Final RMSE on training set: 0.9722090640787552\n",
      "Test RMSE: 1.001716164648987\n"
     ]
    }
   ],
   "source": [
    "mf_sgd = MF_SGD(data=data, test_purpose=True)\n",
    "\n",
    "print('\\nModelling using MF_SGD:')\n",
    "models['mf_sgd'] = mf_sgd.train()['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Matrix Factorization model trained using Biased Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelling using MF_BSGD:\n",
      "Learning the matrix factorization using BSGD ...\n",
      "Iteration: 1, RMSE on training set: 1.0031893656613933\n",
      "Iteration: 2, RMSE on training set: 0.9917689208035846\n",
      "Iteration: 3, RMSE on training set: 0.9840764212615188\n",
      "Iteration: 4, RMSE on training set: 0.9792922297767432\n",
      "Iteration: 5, RMSE on training set: 0.9761765216047489\n",
      "Iteration: 6, RMSE on training set: 0.973157866279339\n",
      "Iteration: 7, RMSE on training set: 0.9713441594690397\n",
      "Iteration: 8, RMSE on training set: 0.9696744429435734\n",
      "Iteration: 9, RMSE on training set: 0.9685373094228283\n",
      "Iteration: 10, RMSE on training set: 0.9673615128082158\n",
      "Iteration: 11, RMSE on training set: 0.9664318851358776\n",
      "Iteration: 12, RMSE on training set: 0.9656141499944134\n",
      "Iteration: 13, RMSE on training set: 0.9650112733199667\n",
      "Iteration: 14, RMSE on training set: 0.9645321669298093\n",
      "Iteration: 15, RMSE on training set: 0.9640508333332661\n",
      "Iteration: 16, RMSE on training set: 0.9636882114236515\n",
      "Iteration: 17, RMSE on training set: 0.9634157912048776\n",
      "Iteration: 18, RMSE on training set: 0.9631517395267248\n",
      "Iteration: 19, RMSE on training set: 0.9629705102372331\n",
      "Iteration: 20, RMSE on training set: 0.9628058496695439\n",
      "... Final RMSE on training set: 0.9628058496695439\n",
      "Test RMSE: 0.9939265798349024\n"
     ]
    }
   ],
   "source": [
    "mf_bsgd = MF_BSGD(data=data, test_purpose=True)\n",
    "\n",
    "print('\\nModelling using MF_BSGD:')\n",
    "models['mf_bsgd'] = mf_bsgd.train()['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Matrix Factorization model trained using Alternating Least Squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelling using MF_ALS:\n",
      "Learning the matrix factorization using ALS ...\n",
      "Iteration: 1, RMSE on training set: 0.984673949906507\n",
      "Iteration: 2, RMSE on training set: 0.969514886406822\n",
      "Iteration: 3, RMSE on training set: 0.9556154436965887\n",
      "Iteration: 4, RMSE on training set: 0.9468573624882057\n",
      "Iteration: 5, RMSE on training set: 0.9427911726103717\n",
      "Iteration: 6, RMSE on training set: 0.9403818073184986\n",
      "Iteration: 7, RMSE on training set: 0.9387652328269936\n",
      "Iteration: 8, RMSE on training set: 0.9376801079932285\n",
      "Iteration: 9, RMSE on training set: 0.9369711988246903\n",
      "Iteration: 10, RMSE on training set: 0.936517493924976\n",
      "Iteration: 11, RMSE on training set: 0.9362331353027183\n",
      "Iteration: 12, RMSE on training set: 0.9360602304304075\n",
      "Iteration: 13, RMSE on training set: 0.9359596492220911\n",
      "Iteration: 14, RMSE on training set: 0.9359052775650721\n",
      "Iteration: 15, RMSE on training set: 0.9358801604599987\n",
      "Iteration: 16, RMSE on training set: 0.9358734638055952\n",
      "The training process converged to a threshold.\n",
      "... Final RMSE on training set: 0.9358734638055952\n",
      "Test RMSE: 0.9827807836575265\n"
     ]
    }
   ],
   "source": [
    "mf_als = MF_ALS(data=data, test_purpose=True)\n",
    "\n",
    "print('\\nModelling using MF_ALS:')\n",
    "models['mf_als'] = mf_als.train()['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Models from Surprise Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_models = SurpriseModels(data=data, test_purpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run neighborhood models from Surprise Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelling using user based Surprise kNN Baseline:\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Test RMSE using Surprise kNN_baseline: 0.997609482251249\n",
      "\n",
      "Modelling using item based Surprise kNN Baseline:\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Test RMSE using Surprise kNN_baseline: 0.9866224991008465\n"
     ]
    }
   ],
   "source": [
    "print('\\nModelling using user based Surprise kNN Baseline:')\n",
    "models['surprise_kNN_baseline_user'] = surprise_models.kNN_baseline(k=100, \n",
    "                                                                    sim_options={'name': 'pearson_baseline',\n",
    "                                                                                 'user_based': True})['Rating']\n",
    "\n",
    "print('\\nModelling using item based Surprise kNN Baseline:')\n",
    "models['surprise_kNN_baseline_item'] = surprise_models.kNN_baseline(k=300, \n",
    "                                                                    sim_options={'name': 'pearson_baseline',\n",
    "                                                                                 'user_based': False})['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run two more simpler models from Surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelling using Surprise SlopeOne:\n",
      "Test RMSE using Surprise slope_one: 0.999198097767189\n",
      "\n",
      "Modelling using Surprise Co-Clustering:\n",
      "Test RMSE using Surprise co_clustering: 1.0100282598031178\n"
     ]
    }
   ],
   "source": [
    "print('\\nModelling using Surprise SlopeOne:')\n",
    "models['surprise_slope_one'] = surprise_models.slope_one()['Rating']\n",
    "\n",
    "#print('\\nModelling using Surprise SVD:')\n",
    "#models['surprise_SVD'] = surprise_models.SVD()['Rating']\n",
    "\n",
    "#print('\\nModelling using Surprise SVD++:')\n",
    "#models['surprise_SVDpp'] = surprise_models.SVDpp()['Rating']\n",
    "\n",
    "print('\\nModelling using Surprise Co-Clustering:')\n",
    "models['surprise_co_clustering'] = surprise_models.co_clustering()['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run blending algorihtm to find the optimal weights for the resulting blended (combined) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelling using weighted averaging of the previous models.\n",
      "     fun: 0.9761825961868279\n",
      "     jac: array([ 1.78217888e-05, -2.65136361e-04,  3.32579017e-04,  1.87158585e-05,\n",
      "        8.75219703e-05,  1.69582665e-04,  7.85216689e-05,  6.29574060e-05,\n",
      "       -9.56803560e-05, -1.75088644e-05,  3.53455544e-05,  1.20326877e-05,\n",
      "       -1.53258443e-05])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 633\n",
      "     nit: 42\n",
      "    njev: 42\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 1.92715920e-01, -4.33729900e-01, -2.98515008e-01,  1.97066800e-01,\n",
      "        1.52011392e-02, -1.89821999e-03, -1.79234920e-01,  3.45241789e-01,\n",
      "        7.33516634e-01,  2.58685080e-01,  3.52442872e-01, -1.81266862e-01,\n",
      "       -5.49359673e-04])\n",
      "\n",
      "Optimal weights:  {'baseline_global_mean': 0.19271591983375924, 'baseline_user_mean': -0.4337299003053698, 'baseline_item_mean': -0.2985150084211989, 'baseline_global_median': 0.1970668001493541, 'baseline_user_median': 0.015201139195270304, 'baseline_item_median': -0.0018982199858547794, 'mf_sgd': -0.17923491952957243, 'mf_bsgd': 0.34524178921797943, 'mf_als': 0.7335166340482717, 'surprise_kNN_baseline_user': 0.2586850797696792, 'surprise_kNN_baseline_item': 0.35244287155037823, 'surprise_slope_one': -0.1812668620103521, 'surprise_co_clustering': -0.0005493596729955596}\n"
     ]
    }
   ],
   "source": [
    "blending = Blending(models, data.test_df['Rating'])\n",
    "\n",
    "print('\\nModelling using weighted averaging of the previous models.')\n",
    "optimal_weights = blending.optimize_weighted_average()\n",
    "print('\\nOptimal weights: ', optimal_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
